{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive, files\n",
    "import zipfile\n",
    "import os\n",
    "import wave\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the drive path\n",
    "drive_path = \"/content/drive/MyDrive/cases_wav_formatted.zip\"\n",
    "\n",
    "# Clear existing files in the target directory\n",
    "if os.path.exists('/content/TTS-TT2/wavs'):\n",
    "    for filename in os.listdir('/content/TTS-TT2/wavs'):\n",
    "        file_path = os.path.join('/content/TTS-TT2/wavs', filename)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "# Create a script for audio processing using ffmpeg\n",
    "with open('/content/audios.sh', 'w') as rsh:\n",
    "    rsh.write('''\\\n",
    "for file in /content/TTS-TT2/wavs/*.wav\n",
    "do\n",
    "    ffmpeg -y -i \"$file\" -ar 22050 /content/tempwav/srtmp.wav -loglevel error\n",
    "    ffmpeg -y -i /content/tempwav/srtmp.wav -c copy -fflags +bitexact -flags:v +bitexact -flags:a +bitexact -ar 22050 /content/tempwav/poop.wav -loglevel error\n",
    "    rm \"$file\"\n",
    "    mv /content/tempwav/poop.wav \"$file\"\n",
    "    rm /content/tempwav/*\n",
    "done\n",
    "''')\n",
    "\n",
    "# Change to the directory where the audios will be stored\n",
    "os.makedirs('/content/TTS-TT2/wavs', exist_ok=True)\n",
    "os.chdir('/content/TTS-TT2/wavs')\n",
    "\n",
    "# Handle audio import\n",
    "drive_path = drive_path.strip()\n",
    "if drive_path:\n",
    "    if os.path.exists(drive_path):\n",
    "        print(f\"\\n\\033[34m\\033[1mAudio imported from Drive.\\n\\033[90m\")\n",
    "        if zipfile.is_zipfile(drive_path):\n",
    "            !unzip -o -q -j \"$drive_path\" -d /content/TTS-TT2/wavs\n",
    "        else:\n",
    "            fp = drive_path + \"/.\"\n",
    "            !cp -a \"$fp\" \"/content/TTS-TT2/wavs\"\n",
    "    else:\n",
    "        print(f\"\\n\\033[33m\\033[1m[NOTICE] The path {drive_path} is not found, check for errors and try again.\")\n",
    "        print(f\"\\n\\033[34m\\033[1mUpload your dataset(audios)...\")\n",
    "        uploaded = files.upload()\n",
    "else:\n",
    "    print(f\"\\n\\033[34m\\033[1mUpload your dataset(audios)...\")\n",
    "    uploaded = files.upload()\n",
    "    for fn in uploaded.keys():\n",
    "        if zipfile.is_zipfile(fn):\n",
    "            !unzip -o -q -j \"$fn\" -d /content/TTS-TT2/wavs\n",
    "            !rm \"$fn\"\n",
    "\n",
    "# Adjust directory if necessary\n",
    "if os.path.exists(\"/content/TTS-TT2/wavs/wavs\"):\n",
    "    for file in os.listdir(\"/content/TTS-TT2/wavs/wavs\"):\n",
    "        !mv /content/TTS-TT2/wavs/wavs/\"$file\"  /content/TTS-TT2/wavs/\"$file\"\n",
    "\n",
    "# Clear or create temporary directory\n",
    "if os.path.exists('/content/tempwav'):\n",
    "    shutil.rmtree('/content/tempwav')\n",
    "os.mkdir('/content/tempwav')\n",
    "\n",
    "# Process audio if required\n",
    "if audio_processing:\n",
    "    print(f\"\\n\\033[37mMetadata removal and audio verification...\")\n",
    "    !bash /content/audios.sh\n",
    "\n",
    "# Analyze audio files\n",
    "totalduration = 0\n",
    "wav_files = [x for x in os.listdir() if os.path.isfile(x) and not x.startswith('._')]\n",
    "for file_name in wav_files:\n",
    "    try:\n",
    "        with wave.open(file_name, \"rb\") as wave_file:\n",
    "            frames = wave_file.getnframes()\n",
    "            rate = wave_file.getframerate()\n",
    "            duration = frames / float(rate)\n",
    "            totalduration += duration\n",
    "\n",
    "            if duration >= 12:\n",
    "                print(f\"\\n\\033[33m\\033[1m[NOTICE] {file_name} is longer than 12 seconds. Lack of RAM can occur in a large batch size!\")\n",
    "    except wave.Error as e:\n",
    "        print(f\"\\n\\033[31m\\033[1m[ERROR] {file_name} is not a valid WAV file: {e}\")\n",
    "\n",
    "# Summary\n",
    "wav_count = len(wav_files)\n",
    "print(f\"\\n{wav_count} processed audios. Total duration: {str(datetime.timedelta(seconds=round(totalduration, 0)))}\\n\")\n",
    "\n",
    "# Print final message\n",
    "print(\"\\n\\033[32m\\033[1mAll set, please proceed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Define model parameters\n",
    "model_filename = 'test'\n",
    "Training_file = \"filelists/list.txt\"\n",
    "output_directory = '/content/drive/MyDrive/colab/outdir'\n",
    "log_directory = '/content/TTS-TT2/logs'\n",
    "log_directory2 = '/content/drive/My Drive/colab/logs'\n",
    "checkpoint_path = os.path.join(output_directory, model_filename)\n",
    "\n",
    "# Hyperparameters\n",
    "hparams = {\n",
    "    'training_files': Training_file,\n",
    "    'validation_files': Training_file,\n",
    "    'p_attention_dropout': 0.1,\n",
    "    'p_decoder_dropout': 0.1,\n",
    "    'decay_start': 15000,\n",
    "    'A_': 3e-4,\n",
    "    'B_': 8000,\n",
    "    'C_': 0,\n",
    "    'min_learning_rate': 1e-5,\n",
    "    'batch_size': 5,\n",
    "    'load_mel_from_disk': True,\n",
    "    'ignore_layers': [],\n",
    "    'epochs': 250,\n",
    "    'cudnn_enabled': True,\n",
    "    'cudnn_benchmark': True,\n",
    "    'text_cleaners': [\"english_cleaners\"],\n",
    "    'show_alignments': True,\n",
    "}\n",
    "\n",
    "# Optionally add CMUDict cleaners\n",
    "use_cmudict = True\n",
    "if use_cmudict:\n",
    "    hparams['text_cleaners'].append(\"cmudict_cleaners\")\n",
    "\n",
    "# Ensure CUDA is configured correctly\n",
    "torch.backends.cudnn.enabled = hparams['cudnn_enabled']\n",
    "torch.backends.cudnn.benchmark = hparams['cudnn_benchmark']\n",
    "\n",
    "# Display configuration\n",
    "print(\"Model Filename:\", model_filename)\n",
    "print(\"Training File:\", Training_file)\n",
    "print(\"Hyperparameters:\", hparams)\n",
    "print(\"Output Directory:\", output_directory)\n",
    "print(\"Log Directory:\", log_directory)\n",
    "print(\"Checkpoint Path:\", checkpoint_path)\n",
    "\n",
    "# Note: Further training steps would be required here, such as initializing the model,\n",
    "# loading data, and starting the training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import shutil\n",
    "\n",
    "# Function to remove `._` files\n",
    "def remove_dot_underscore_files(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith('._'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Removed {file_path}\")\n",
    "\n",
    "# Function to create Mel spectrograms from .WAV files\n",
    "def create_mels():\n",
    "    wav_dir = '/content/TTS-TT2/wavs'\n",
    "    mel_dir = '/content/TTS-TT2/mels'\n",
    "    os.makedirs(mel_dir, exist_ok=True)\n",
    "\n",
    "    for wav_file in os.listdir(wav_dir):\n",
    "        if wav_file.endswith('.wav') and not wav_file.startswith('._'):\n",
    "            wav_path = os.path.join(wav_dir, wav_file)\n",
    "            mel_path = os.path.join(mel_dir, wav_file.replace('.wav', '.npy'))\n",
    "\n",
    "            try:\n",
    "                # Load the audio file\n",
    "                y, sr = librosa.load(wav_path, sr=22050)\n",
    "                # Compute the Mel spectrogram\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80)\n",
    "                mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "                # Save the Mel spectrogram as a .npy file\n",
    "                np.save(mel_path, mel_spectrogram_db)\n",
    "                print(f\"Converted {wav_file} to Mel spectrogram and saved as {mel_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {wav_file}: {e}\")\n",
    "\n",
    "# Function to check the dataset for missing files\n",
    "def check_dataset(hparams):\n",
    "    training_files = hparams['training_files']\n",
    "    validation_files = hparams['validation_files']\n",
    "    \n",
    "    missing_files = []\n",
    "    \n",
    "    def check_filelist(filelist):\n",
    "        with open(filelist, 'r') as f:\n",
    "            for line in f:\n",
    "                mel_file = line.strip().split('|')[0]\n",
    "                if not os.path.exists(mel_file):\n",
    "                    missing_files.append(mel_file)\n",
    "\n",
    "    check_filelist(training_files)\n",
    "    check_filelist(validation_files)\n",
    "\n",
    "    if missing_files:\n",
    "        print(f\"Missing Mel spectrogram files: {missing_files}\")\n",
    "    else:\n",
    "        print(\"All Mel spectrogram files are present.\")\n",
    "\n",
    "# Parameters\n",
    "generate_mels = True\n",
    "\n",
    "# Remove `._` files\n",
    "remove_dot_underscore_files('/content/TTS-TT2/wavs')\n",
    "\n",
    "# Convert .WAV files to Mel spectrograms if required\n",
    "if generate_mels:\n",
    "    create_mels()\n",
    "\n",
    "print(\"Checking for missing files\")\n",
    "\n",
    "# Replace .wav with .npy in filelists\n",
    "!sed -i -- 's,.wav|,.npy|,g' {hparams['training_files']}; sed -i -- 's,.wav|,.npy|,g' {hparams['validation_files']}\n",
    "\n",
    "# Check the dataset\n",
    "check_dataset(hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def train(output_directory, log_directory, checkpoint_path, warm_start, n_gpus, rank, group_name, hparams, log_directory2, save_interval, backup_interval):\n",
    "    \"\"\"Training and validation logging results to tensorboard and stdout\n",
    "    \n",
    "    \"\"\"\n",
    "    if hparams['distributed_run']:\n",
    "        init_distributed(hparams, n_gpus, rank, group_name)\n",
    "\n",
    "    torch.manual_seed(hparams['seed'])\n",
    "    torch.cuda.manual_seed(hparams['seed'])\n",
    "\n",
    "    model = load_model(hparams)\n",
    "    learning_rate = hparams['learning_rate']\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                                 weight_decay=hparams['weight_decay'])\n",
    "\n",
    "    if hparams['fp16_run']:\n",
    "        from apex import amp\n",
    "        model, optimizer = amp.initialize(\n",
    "            model, optimizer, opt_level='O2')\n",
    "\n",
    "    if hparams['distributed_run']:\n",
    "        model = apply_gradient_allreduce(model)\n",
    "\n",
    "    criterion = Tacotron2Loss()\n",
    "\n",
    "    logger = prepare_directories_and_logger(\n",
    "        output_directory, log_directory, rank)\n",
    "\n",
    "    train_loader, valset, collate_fn = prepare_dataloaders(hparams)\n",
    "\n",
    "    # Load checkpoint \n",
    "    iteration = 0\n",
    "    epoch_offset = 0\n",
    "    if checkpoint_path is not None and os.path.isfile(checkpoint_path):\n",
    "        if warm_start:\n",
    "            model = warm_start_model(\n",
    "                checkpoint_path, model, hparams['ignore_layers'])\n",
    "        else:\n",
    "            model, optimizer, _learning_rate, iteration = load_checkpoint(\n",
    "                checkpoint_path, model, optimizer)\n",
    "            if hparams['use_saved_learning_rate']:\n",
    "                learning_rate = _learning_rate\n",
    "            iteration += 1  # next iteration is iteration + 1\n",
    "            epoch_offset = max(0, int(iteration / len(train_loader)))\n",
    "    else:\n",
    "        pretrained_model_path = \"/content/TTS-TT2/pretrained_model\"\n",
    "        if not os.path.isfile(pretrained_model_path):\n",
    "            !/content/TTS-TT2/megadown.sh https://mega.nz/#!WXY3RILA!KyoGHtfB_sdhmLFoykG2lKWhh0GFdwMkk7OwAjpQHRo --o pretrained_model\n",
    "        model = warm_start_model(pretrained_model_path, model, hparams['ignore_layers'])\n",
    "        # download LJSpeech pretrained model \n",
    "\n",
    "    start_eposh = time.perf_counter()\n",
    "    learning_rate = 0.0\n",
    "    model.train()\n",
    "    is_overflow = False\n",
    "    \n",
    "    for epoch in tqdm(range(epoch_offset, hparams['epochs'])):\n",
    "        print(\"\\nStarting Epoch: {} Iteration: {}\".format(epoch, iteration))\n",
    "        start_eposh = time.perf_counter() # eposh is russian, not a typo\n",
    "        for i, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            start = time.perf_counter()\n",
    "            if iteration < hparams['decay_start']: learning_rate = hparams['A_']\n",
    "            else: iteration_adjusted = iteration - hparams['decay_start']; learning_rate = (hparams['A_']*(math.exp(-iteration_adjusted/hparams['B_']))) + hparams['C_']\n",
    "            learning_rate = max(hparams['min_learning_rate'], learning_rate) # output the largest number\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = learning_rate\n",
    "\n",
    "            model.zero_grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources used for code, models, ideas implemented: NVDIA NEMO Guides, Pony Preservation Project, NVIDIA Deep learning. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
